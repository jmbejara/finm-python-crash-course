{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 Factor Analysis on Financial and Economic Time Series\n",
    "\n",
    "Factor Analysis and Principal Component Analysis on Financial and Economic Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running this on Colab, make sure to install the following packages using pip.\n",
    "# On you're own computer, I recommend using conda or mamba.\n",
    "\n",
    "# !pip install pandas-datareader\n",
    "# !pip install yfinance\n",
    "\n",
    "# !conda install pandas-datareader\n",
    "# !conda install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas_datareader as pdr\n",
    "import sklearn.decomposition\n",
    "import statsmodels.multivariate.pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "DATA_DIR = config.DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading macroeconomic and financial data from FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fred_series_long_names = {\n",
    "    'BAMLH0A0HYM2': 'ICE BofA US High Yield Index Option-Adjusted Spread',\n",
    "    'NASDAQCOM': 'NASDAQ Composite Index',\n",
    "    'RIFSPPFAAD90NB': '90-Day AA Financial Commercial Paper Interest Rate',\n",
    "    'TB3MS': '3-Month Treasury Bill Secondary Market Rate',\n",
    "    'DGS10': 'Market Yield on U.S. Treasury Securities at 10-Year Constant Maturity',\n",
    "    'VIXCLS': 'CBOE Volatility Index: VIX',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fred_series_short_names = {\n",
    "    'BAMLH0A0HYM2': 'High Yield Index OAS',\n",
    "    'NASDAQCOM': 'NASDAQ',\n",
    "    'RIFSPPFAAD90NB': '90-Day AA Fin CP',\n",
    "    'TB3MS': '3-Month T-Bill',\n",
    "    'DGS10': '10-Year Treasury',\n",
    "    'VIXCLS': 'VIX',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('1980-01-01') \n",
    "end_date = pd.to_datetime('today') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pdr.get_data_fred(fred_series_short_names.keys(), start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, an aside about reading and writing data to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATA_DIR / 'fred_panel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv(DATA_DIR / 'fred_panel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv(DATA_DIR / 'fred_panel.csv', parse_dates=['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.set_index('DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(DATA_DIR / 'fred_panel.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_DIR / 'fred_panel.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dff.rename(columns=fred_series_short_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced panel? Mixed frequencies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['3-Month T-Bill'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a daily version of this series. See here: https://fred.stlouisfed.org/categories/22\n",
    "\n",
    "We will end up using this series: https://fred.stlouisfed.org/series/DTB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fred_series_short_names = {\n",
    "    'BAMLH0A0HYM2': 'High Yield Index OAS',\n",
    "    'NASDAQCOM': 'NASDAQ',\n",
    "    'RIFSPPFAAD90NB': '90-Day AA Fin CP',\n",
    "    'DTB3': '3-Month T-Bill',\n",
    "    'DGS10': '10-Year Treasury',\n",
    "    'VIXCLS': 'VIX',\n",
    "}\n",
    "df = pdr.get_data_fred(fred_series_short_names.keys(), start=start_date, end=end_date)\n",
    "df = df.rename(columns=fred_series_short_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming and Normalizing the data\n",
    "\n",
    "What is transformation and normalization? Are these different things?\n",
    "\n",
    " - Why would one transform data? What is feature engineering?\n",
    " - What is normalization?\n",
    "\n",
    "What does stationarity mean? See the the following plots. Some of these variable are stationary. Other are not? Why is this a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['NASDAQ']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some transformations like those used in the OFR Financial Stress Index: https://www.financialresearch.gov/financial-stress-index/files/indicators/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = pd.DataFrame().reindex_like(df)\n",
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NASDAQ'].rolling(250).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NASDAQ'].rolling(250).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'High Yield Index OAS': Leave as is\n",
    "dfn['High Yield Index OAS'] = df['High Yield Index OAS']\n",
    "dfn['CP - Treasury Spread, 3m'] = df['90-Day AA Fin CP'] - df['3-Month T-Bill']\n",
    "# 'NASDAQ':  # We're using something different, but still apply rolling mean transformation\n",
    "dfn['NASDAQ'] = np.log(df['NASDAQ']) - np.log(df['NASDAQ'].rolling(250).mean())\n",
    "dfn['10-Year Treasury'] = df['10-Year Treasury'] - df['10-Year Treasury'].rolling(250).mean()\n",
    "# 'VIX': Leave as is\n",
    "dfn['VIX'] = df['VIX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = dfn.drop(columns=['90-Day AA Fin CP', '3-Month T-Bill'])\n",
    "dfn = dfn.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finished with our transformations. Now, let's normalize. First, why is it important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, normalize each column,\n",
    "$$\n",
    "z = \\frac{x - \\bar x}{\\text{std}(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = (dfn - dfn.mean()) / dfn.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(dfn, module='scikitlearn'):\n",
    "    if module == 'statsmodels':\n",
    "        _pc1, _loadings, projection, rsquare, _, _, _ = statsmodels.multivariate.pca.pca(dfn,\n",
    "            ncomp=1, standardize=True, demean=True, normalize=True, gls=False,\n",
    "            weights=None, method='svd')\n",
    "        _loadings = _loadings['comp_0']\n",
    "        loadings = np.std(_pc1) * _loadings\n",
    "        pc1 = _pc1 / np.std(_pc1)\n",
    "        pc1 = pc1.rename(columns={'comp_0':'PC1'})['PC1']\n",
    "\n",
    "    elif module == 'scikitlearn':\n",
    "        pca = sklearn.decomposition.PCA(n_components=1)\n",
    "        _pc1 = pd.Series(pca.fit_transform(dfn)[:,0], index=dfn.index, name='PC1')\n",
    "        _loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "        _loadings = pd.Series(_loadings[:,0], index=dfn.columns)\n",
    "\n",
    "        loadings = np.std(_pc1) * _loadings\n",
    "        pc1 = _pc1 / np.std(_pc1)\n",
    "        pc1.name = 'PC1'\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "\n",
    "    loadings.name = \"loadings\"\n",
    "\n",
    "    return pc1, loadings\n",
    "\n",
    "def stacked_plot(df, filename=None):\n",
    "    \"\"\"\n",
    "    df=category_contributions\n",
    "    # category_contributions.sum(axis=1).plot()\n",
    "    \"\"\"\n",
    "\n",
    "    df_pos = df[df >= 0]\n",
    "    df_neg = df[df < 0]\n",
    "\n",
    "    alpha = .3\n",
    "    linewidth = .5\n",
    "\n",
    "    ax = df_pos.plot.area(alpha=alpha, linewidth=linewidth, legend=False)\n",
    "    pc1 = df.sum(axis=1)\n",
    "    pc1.name = 'pc1'\n",
    "    pc1.plot(color=\"Black\", label='pc1', linewidth=1)\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    ax.set_prop_cycle(None)\n",
    "    df_neg.plot.area(alpha=alpha, ax=ax, linewidth=linewidth, legend=False, ylim=(-3,3))\n",
    "    # recompute the ax.dataLim\n",
    "    ax.relim()\n",
    "    # update ax.viewLim using the new dataLim\n",
    "    ax.autoscale()\n",
    "    # ax.set_ylabel('Standard Deviations')\n",
    "    # ax.set_ylim(-3,4)\n",
    "    # ax.set_ylim(-30,30)\n",
    "\n",
    "    if not (filename is None):\n",
    "        filename = Path(filename)\n",
    "        figure = plt.gcf() # get current figure\n",
    "        figure.set_size_inches(8, 6)\n",
    "        plt.savefig(filename, dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1, loadings = pca(dfn, module='scikitlearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_plot(dfn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare solutions from two different packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(sa, sb):\n",
    "    return np.sqrt(np.mean((sa - sb)**2))\n",
    "\n",
    "pc1_sk, loadings_sk = pca(dfn, module='scikitlearn')\n",
    "pc1_sm, loadings_sm = pca(dfn, module='statsmodels')\n",
    "root_mean_squared_error(pc1_sm, pc1_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Analysis of a Panel of Stock Returns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample data for multiple tickers\n",
    "# Note: yfinance may return different structures depending on version and number of tickers\n",
    "sample = yf.download(\"SPY AAPL MSFT\", start=\"2017-01-01\", end=\"2017-04-30\", progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the structure of the downloaded data\n",
    "print(\"Sample columns:\", sample.columns.tolist() if hasattr(sample, 'columns') else 'No columns attribute')\n",
    "print(\"Sample shape:\", sample.shape if hasattr(sample, 'shape') else 'No shape attribute')\n",
    "if hasattr(sample, 'columns') and isinstance(sample.columns, pd.MultiIndex):\n",
    "    print(\"Column levels:\", sample.columns.levels)\n",
    "    print(\"First level values:\", sample.columns.levels[0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When downloading multiple tickers, yfinance returns a DataFrame with MultiIndex columns\n",
    "# The first level is the data type (e.g., 'Adj Close'), the second level is the ticker\n",
    "# Display the adjusted close prices for all tickers\n",
    "adj_close_data = sample['Adj Close'] if 'Adj Close' in sample.columns.get_level_values(0) else sample\n",
    "adj_close_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\n",
    "    'AAPL','ABBV','ABT','ACN','ADP','ADSK','AES','AET','AFL','AMAT','AMGN','AMZN','APA',\n",
    "    'APHA','APD','APTV','ARE','ASML','ATVI','AXP','BA','BAC','BAX','BDX','BIIB','BK',\n",
    "    'BKNG','BMY','BRKB','BRK.A','COG','COST','CPB','CRM','CSCO','CVS','DAL','DD','DHR',\n",
    "    'DIS','DOW','DUK','EMR','EPD','EQT','ESRT','EXPD','FFIV','FLS','FLT','FRT','GE',\n",
    "    'GILD','GOOGL','GOOG','GS','HAL','HD','HON','IBM','INTC','IP','JNJ','JPM','KEY',\n",
    "    'KHC','KIM','KO','LLY','LMT','LOW','MCD','MCHP','MDT','MMM','MO','MRK','MSFT',\n",
    "    'MTD','NEE','NFLX','NKE','NOV','ORCL','OXY','PEP','PFE','PG','RTN','RTX','SBUX',\n",
    "    'SHW','SLB','SO','SPG','STT','T','TGT','TXN','UNH','UPS','USB','UTX','V','VZ',\n",
    "    'WMT','XOM',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" \".join(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(\" \".join(tickers), start=\"1980-01-01\", end=pd.to_datetime('today'), progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Adj Close']['AAPL'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_many_nas = [\n",
    "    \"BRK.A\",\n",
    "    \"APHA\",\n",
    "    \"UTX\",\n",
    "    \"RTN\",\n",
    "    \"COG\",\n",
    "    \"BRKB\",\n",
    "    \"ATVI\",\n",
    "    \"FLT\",\n",
    "    \"DOW\",\n",
    "    \"KHC\",\n",
    "    \"V\",\n",
    "    \"APTV\",\n",
    "    \"ABBV\",\n",
    "    \"ESRT\",\n",
    "]\n",
    "df = data['Adj Close']\n",
    "print(f\"Initial shape: {df.shape}\")\n",
    "df = df.drop(columns=cols_with_many_nas, errors='ignore')\n",
    "print(f\"After dropping columns: {df.shape}\")\n",
    "df = df.dropna()\n",
    "print(f\"After first dropna: {df.shape}\")\n",
    "df = df.pct_change()\n",
    "print(f\"After pct_change: {df.shape}\")\n",
    "df = df.dropna()\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "\n",
    "# If DataFrame is empty, use a smaller date range or fewer tickers\n",
    "if df.empty:\n",
    "    print(\"DataFrame is empty! Trying with fewer tickers and recent data...\")\n",
    "    simple_tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']\n",
    "    data = yf.download(\" \".join(simple_tickers), start=\"2020-01-01\", end=pd.to_datetime('today'), progress=False)\n",
    "    df = data['Adj Close'].pct_change().dropna()\n",
    "    print(f\"New shape with simple tickers: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AAPL'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    pc1, loadings = pca(df, module='scikitlearn')\n",
    "    print(f\"PCA completed successfully. PC1 shape: {pc1.shape}\")\n",
    "else:\n",
    "    print(\"Cannot run PCA on empty DataFrame!\")\n",
    "    pc1 = pd.Series(dtype=float)\n",
    "    loadings = pd.Series(dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pc1.empty:\n",
    "    pc1.plot()\n",
    "else:\n",
    "    print(\"No data to plot for PC1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pc1.empty:\n",
    "    pc1.cumsum().plot()\n",
    "else:\n",
    "    print(\"No data to plot for cumulative PC1\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
